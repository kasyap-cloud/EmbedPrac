{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence_transformers in /home/krishna/.local/lib/python3.10/site-packages (4.0.1)\n",
      "Requirement already satisfied: scipy in /home/krishna/.local/lib/python3.10/site-packages (from sentence_transformers) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn in /home/krishna/.local/lib/python3.10/site-packages (from sentence_transformers) (1.6.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/krishna/.local/lib/python3.10/site-packages (from sentence_transformers) (2.4.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/krishna/.local/lib/python3.10/site-packages (from sentence_transformers) (4.49.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/krishna/.local/lib/python3.10/site-packages (from sentence_transformers) (0.29.3)\n",
      "Requirement already satisfied: tqdm in /home/krishna/.local/lib/python3.10/site-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/krishna/.local/lib/python3.10/site-packages (from sentence_transformers) (4.12.2)\n",
      "Requirement already satisfied: Pillow in /home/krishna/.local/lib/python3.10/site-packages (from sentence_transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in /home/krishna/.local/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.18.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/krishna/.local/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
      "Requirement already satisfied: requests in /home/krishna/.local/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/krishna/.local/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (5.4.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/krishna/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: networkx in /home/krishna/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/krishna/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
      "Requirement already satisfied: sympy in /home/krishna/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/krishna/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/krishna/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/krishna/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.0.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/krishna/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/krishna/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/krishna/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/krishna/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/krishna/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/krishna/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/krishna/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/krishna/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/krishna/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.4.127)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/krishna/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.2.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/krishna/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/krishna/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/krishna/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/krishna/.local/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/krishna/.local/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/krishna/.local/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/krishna/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2025.1.31)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/krishna/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (1.26.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/krishna/.local/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishna/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.6333\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "sentence1 = \"I am a machine learning engineer.\"\n",
    "sentence2 = \"I develop AI models.\"\n",
    "\n",
    "embedding1 = model.encode(sentence1, convert_to_tensor=True)\n",
    "embedding2 = model.encode(sentence2, convert_to_tensor=True)\n",
    "\n",
    "cos_sim = util.cos_sim(embedding1, embedding2)\n",
    "print(f\"Cosine Similarity: {cos_sim.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = \"\"\"\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque ac feugiat urna. \n",
    "Sed ullamcorper mi sed nunc eleifend, et gravida erat fermentum. \n",
    "Phasellus sit amet ipsum non odio gravida auctor in eu nisl. Aliquam erat volutpat. \n",
    "Integer feugiat magna non felis cursus, id facilisis eros aliquam. \n",
    "Proin tempor magna in risus sollicitudin, vitae faucibus nisi fermentum. \n",
    "Mauris tincidunt risus id dui dictum, at lacinia lorem blandit. \n",
    "Nam sit amet dictum metus. Morbi vel fermentum orci, ut interdum nulla.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = model.encode(para, convert_to_numpy=True)\n",
    "embeddings = model.encode(para)\n",
    "embeddings = np.array(embeddings).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Step 1: Generate some sample text data and convert to embeddings\n",
    "texts = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Faiss is an efficient similarity search library.\",\n",
    "    \"Embedding models help convert text into vectors.\"\n",
    "]\n",
    "\n",
    "# Use Sentence-Transformers to convert text into embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(texts)\n",
    "\n",
    "# Convert embeddings to float32 (Faiss requires float32)\n",
    "embeddings = np.array(embeddings).astype('float32')\n",
    "\n",
    "# Step 2: Create Faiss index\n",
    "dimension = embeddings.shape[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 384)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document inserted with ID: AeYhOZYB8vi0NbiMmTG6\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Connect\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "# Create index (auto-created on first document insert if it doesn't exist)\n",
    "index_name = \"simple_index\"\n",
    "\n",
    "# Optional: define a simple mapping (skip if default mapping is okay)\n",
    "if not es.indices.exists(index=index_name):\n",
    "    es.indices.create(index=index_name)\n",
    "\n",
    "# Insert document\n",
    "doc = {\"title\": \"Elasticsearch is awesome\", \"category\": \"search engine\"}\n",
    "res = es.index(index=index_name, document=doc)\n",
    "\n",
    "print(\"Document inserted with ID:\", res['_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
